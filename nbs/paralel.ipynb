{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8998a0eb-2647-4dea-abf5-ff6690b457f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# default_exp paralel"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00de67c2-331a-4946-8e8e-9ed94964b261",
   "metadata": {},
   "source": [
    "# Pararel Downloading\n",
    "\n",
    "This define a paralel executor for the downloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d22126b4-b78c-4ce3-ba5e-38111af9a1bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# hide\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f667b66-c79b-4ae1-b90e-93b21a00c369",
   "metadata": {},
   "outputs": [],
   "source": [
    "# hide\n",
    "from nbdev.showdoc import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25ab140d-844f-42c6-9157-d04b2ebf0b9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "import time\n",
    "from threading import Thread\n",
    "from typing import List\n",
    "\n",
    "from docarray import Document, DocumentArray\n",
    "from rich.progress import Progress\n",
    "\n",
    "from web2dataset.downloader import Downloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a35191be-fc63-4592-9e83-88efd6a96853",
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "class ParalelDownload:\n",
    "    def __init__(\n",
    "        self,\n",
    "        path: str,\n",
    "        downloader_cls: type[Downloader],\n",
    "        num_workers: int,\n",
    "        dataset_fn: str = \"dataset.bin\",\n",
    "        *args,\n",
    "        **kwargs,\n",
    "    ):\n",
    "        \"\"\"Parallelize donwloading\n",
    "        path: folder in which to save the files\n",
    "        downloader_cls: the class of Downloader you want to parellize\n",
    "        num_workers: the number of worker to use.\n",
    "        dataset_fn: name of the file in which to save the docarray dataset, by default dataset.bin\n",
    "        silence: to silence the logging and the progress bar\n",
    "        *args: args to pass to the downloader\n",
    "        *kwargs: kwargs to pass to the downloader\n",
    "        \"\"\"\n",
    "\n",
    "        self.path = path\n",
    "        self.dataset_fn = dataset_fn\n",
    "        self.num_workers = num_workers\n",
    "        self.downloaders = [\n",
    "            downloader_cls(path=path, *args, **kwargs) for i in range(num_workers)\n",
    "        ]\n",
    "\n",
    "    def download(\n",
    "        self,\n",
    "        queries: List[str],\n",
    "        n_item: int,\n",
    "        silence: bool = False,\n",
    "    ):\n",
    "        with Progress(disable=silence) as progress:\n",
    "\n",
    "            for i, _ in enumerate(self.downloaders):\n",
    "                progress.add_task(f\"Scrapping {queries[i]} ...\", total=n_item)\n",
    "\n",
    "            def task(downloader, task_id):\n",
    "                while query := queries.pop() if queries else False:\n",
    "                    downloader._download(query, n_item, progress, task_id)\n",
    "\n",
    "            threads = []\n",
    "            for task_id, downloader in enumerate(self.downloaders):\n",
    "                threads.append(\n",
    "                    Thread(\n",
    "                        target=task,\n",
    "                        args=(\n",
    "                            downloader,\n",
    "                            task_id,\n",
    "                        ),\n",
    "                    )\n",
    "                )\n",
    "                threads[-1].start()\n",
    "\n",
    "            for t in threads:\n",
    "                t.join()\n",
    "\n",
    "            with open(f\"{self.path}/{self.dataset_fn}\", \"wb\") as f:\n",
    "                self.docs = DocumentArray().empty()\n",
    "                for d in self.downloaders:\n",
    "                    self.docs.extend(d.docs)\n",
    "                f.write(self.docs.to_bytes())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20974181-0fc4-4c53-b064-07b2cb24f0fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_folder = \"/tmp/test_paralel\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ef75f38-8b5b-42c1-b710-5fb661f9a6e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# hide\n",
    "import shutil\n",
    "\n",
    "shutil.rmtree(test_folder, ignore_errors=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ab112b8-e8f4-4074-881d-523859a5f119",
   "metadata": {},
   "source": [
    "let's define first a downloader to test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0754562a-4a24-48a8-991f-270fd45482ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "\n",
    "class BasicDownloader(Downloader):\n",
    "    def _download(self, query: str, n_item: int, progress: Progress, task_id: int = 0):\n",
    "        time.sleep(0.5)\n",
    "        self.docs.extend(\n",
    "            (Document(tag={\"origin\": \"https://www.google.fr\"}) for _ in range(n_item))\n",
    "        )\n",
    "        progress.update(task_id, advance=n_item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cfb52cf-1c62-4315-861a-89ad2131dd21",
   "metadata": {},
   "outputs": [],
   "source": [
    "paralel_down = ParalelDownload(f\"{test_folder}/my_search\", BasicDownloader, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd12d5c7-bbe7-452b-8df8-4300086e185c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bb408bfddbea4d128c0a49affacb9f33",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 135 ms, sys: 3.23 ms, total: 138 ms\n",
      "Wall time: 1.03 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "paralel_down.download([\"a\", \"b\", \"c\", \"d\"], 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88b9d6ff-2432-4eb8-adaa-73657de65924",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert len(paralel_down.docs) == 12"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
