{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77ef3c64-5ed7-4ba9-9da7-81419b3d92f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# default_exp cleaner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c246c5e-47a9-4ca5-88d8-b5bca48afed7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# hide\n",
    "from nbdev.showdoc import *"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f67349d9-d059-40fd-8c23-f72a9b3f83aa",
   "metadata": {},
   "source": [
    "# Cleaner\n",
    "\n",
    "> The clearners are the last but not least blocks of web2dataset. Their goal is to purge and clean the dataset.\n",
    "\n",
    "Example of cleaner (not yet implemented):\n",
    "\n",
    "* delete double (based on hash)\n",
    "* delete image with low resolution\n",
    "* ethic base purger, how to ?\n",
    "\n",
    "There are two kind of cleaner, the one that work on metadata that are called before downloading the image and the one that work on image and are called after\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58b344f2-80c9-4f91-b9bd-ac37015fc134",
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "from functools import wraps\n",
    "from typing import List\n",
    "\n",
    "from web2dataset.document import Document"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e8eb7bd-f1da-4267-93a6-405b62feb0c6",
   "metadata": {},
   "source": [
    "# MetaDataCleaner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0013013-0d3c-465f-b85d-7e0b8c737be6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "class MetaDataCleanerError(ValueError):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f5c87c1-78c2-45bc-ac7b-b8dd3b6255dd",
   "metadata": {},
   "source": [
    "a cleaner should delete docs not create them, so we verify than we did not create new docs with this wrapper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c576b143-a95a-4c0b-bcea-a39408bbac90",
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "def check_no_docs_creation(f):\n",
    "    @wraps(f)\n",
    "    def wrapper(self, docs: List[Document]) -> List[Document]:\n",
    "        new_docs = f(self, docs)\n",
    "        if len(new_docs) > len(docs):\n",
    "            raise MetaDataCleanerError(\n",
    "                f\"the cleaner should not create more docs than originaly. There were before {len(docs)} docs and there are now {len(new_docs)} docs\"\n",
    "            )\n",
    "        return new_docs\n",
    "\n",
    "    return wrapper"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65a4ee6c-dd5d-462b-8e0f-fdada9be799d",
   "metadata": {},
   "source": [
    "Here is the abstract class for the meta data cleaner. It only operate on documents not images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "091f0262-3d27-4307-ad28-8a2cfc59965c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "class MetaDataCleaner:\n",
    "    @check_no_docs_creation\n",
    "    def clean(self, docs: List[Document]) -> List[Document]:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d77afae-5889-4c32-bcff-c89da5f605b3",
   "metadata": {},
   "source": [
    "here is a basic cleaner that is mainly used for testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d16abd3-09e5-4f08-95c6-56c4e1eb8cc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "class IdentityCleaner:\n",
    "    @check_no_docs_creation\n",
    "    def clean(self, docs: List[Document]) -> List[Document]:\n",
    "        return docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14ee6f3f-6597-461f-9438-00dc67ca7fdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "docs = [\n",
    "    Document(origin=\"\", image_url=\"https://image/bike\"),\n",
    "    Document(origin=\"\", image_url=\"https://image/bike\"),\n",
    "    Document(origin=\"\", image_url=\"https://image/bmx\"),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "482fd352-670b-4f36-aeb1-c56a50b05865",
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaner = IdentityCleaner()\n",
    "docs = cleaner.clean(docs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "526e65dd-7578-4669-b61d-0233177d8e8b",
   "metadata": {},
   "source": [
    "## Duplicate cleaner"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41aa25d5-1bd6-4383-b878-9ac82f823829",
   "metadata": {},
   "source": [
    "This MetaDataDuplicateCleaner delete any duplicate, i.e document with the same src image to avoid downloading twice the same image.\n",
    "It is different from the ImageDuplicateCleaner, will delete two identical image after the donwload, this images could come from two different sources be still be the same"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "298713fa-5aaf-4e08-bbb1-f9459ca52f17",
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "class DuplicateCleaner(MetaDataCleaner):\n",
    "    @check_no_docs_creation\n",
    "    def clean(self, docs: List[Document]) -> List[Document]:\n",
    "        url_doc = {\n",
    "            doc.image_url: doc for doc in docs\n",
    "        }  # first we create a dict with image url as key because we want to keep only one doc per image_rul\n",
    "        return list(url_doc.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e29844d4-767b-4623-b9b2-f5ccdffaccd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "docs = [\n",
    "    Document(origin=\"\", image_url=\"https://image/bike\"),\n",
    "    Document(origin=\"\", image_url=\"https://image/bike\"),\n",
    "    Document(origin=\"\", image_url=\"https://image/bmx\"),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39206222-a04b-4235-99d0-0540a234ec41",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3, 2)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "url = [doc.image_url for doc in docs]\n",
    "len(url), len(set(url))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26de54ae-1f7b-40c1-925b-bb8050fe167e",
   "metadata": {},
   "source": [
    "as we can see in this list of doc there are 3 url but only two of them are different. Let's fix it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2bd3fa7-cb52-499f-b333-b0ea2a53ffbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaner = DuplicateCleaner()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3079f90e-b875-470c-b537-77b075cb3b8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "docs2 = cleaner.clean(docs)\n",
    "url = [doc.image_url for doc in docs2]\n",
    "\n",
    "assert len(url) == len(set(url))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7792dd25-a171-431d-9345-30a72df7fc74",
   "metadata": {},
   "source": [
    "# ImageCleaner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24f77f56-b4c7-443b-8ec5-885ae1cca3bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "class ImageCleaner:\n",
    "    def __init__(self, path: str):\n",
    "        self.path = path\n",
    "\n",
    "    def clean(self):\n",
    "        pass"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
