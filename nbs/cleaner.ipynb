{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77ef3c64-5ed7-4ba9-9da7-81419b3d92f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# default_exp cleaner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c246c5e-47a9-4ca5-88d8-b5bca48afed7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# hide\n",
    "from nbdev.showdoc import *"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f67349d9-d059-40fd-8c23-f72a9b3f83aa",
   "metadata": {},
   "source": [
    "# Cleaner\n",
    "\n",
    "> The clearners are the last but not least blocks of web2dataset. Their goal is to purge and clean the dataset.\n",
    "\n",
    "Example of cleaner (not yet implemented):\n",
    "\n",
    "* delete double (based on hash)\n",
    "* delete image with low resolution\n",
    "* ethic base purger, how to ?\n",
    "\n",
    "There are two kind of cleaner, the one that work on metadata that are called before downloading the image and the one that work on image and are called after\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58b344f2-80c9-4f91-b9bd-ac37015fc134",
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "from typing import List\n",
    "\n",
    "from web2dataset.document import Document"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e8eb7bd-f1da-4267-93a6-405b62feb0c6",
   "metadata": {},
   "source": [
    "# MetaDataCleaner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "091f0262-3d27-4307-ad28-8a2cfc59965c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "class MetaDataCleaner:    \n",
    "    def clean(self, docs : List[Document]) -> List[Document]:\n",
    "        pass\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "526e65dd-7578-4669-b61d-0233177d8e8b",
   "metadata": {},
   "source": [
    "## Duplicate cleaner"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41aa25d5-1bd6-4383-b878-9ac82f823829",
   "metadata": {},
   "source": [
    "This MetaDataDuplicateCleaner delete any duplicate, i.e document with the same src image to avoid downloading twice the same image.\n",
    "It is different from the ImageDuplicateCleaner, will delete two identical image after the donwload, this images could come from two different sources be still be the same"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "298713fa-5aaf-4e08-bbb1-f9459ca52f17",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MetaDataDuplicateCleaner(MetaDataCleaner):\n",
    "    \n",
    "    def clean(self, docs : List[Document]) -> List[Document]:\n",
    "        url_doc = { doc.image_url:doc for doc in docs} # first we create a dict with image url as key because we want to keep only one doc per image_rul\n",
    "        return list(url_doc.values())\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e29844d4-767b-4623-b9b2-f5ccdffaccd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "docs = [ Document(origin=\"\",image_url=\"https://image/bike\"),Document(origin=\"\",image_url=\"https://image/bike\"),Document(origin=\"\",image_url=\"https://image/bmx\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39206222-a04b-4235-99d0-0540a234ec41",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3, 2)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "url = [ doc.image_url for doc in docs]\n",
    "len(url),len(set(url))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26de54ae-1f7b-40c1-925b-bb8050fe167e",
   "metadata": {},
   "source": [
    "as we can see in this list of doc there are 3 url but only two of them are different. Let's fix it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2bd3fa7-cb52-499f-b333-b0ea2a53ffbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaner= MetaDataDuplicateCleaner()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3079f90e-b875-470c-b537-77b075cb3b8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "docs2 = cleaner.clean(docs)\n",
    "url = [ doc.image_url for doc in docs2]\n",
    "\n",
    "assert len(url) == len(set(url))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ef3934f-9924-4ba4-a79e-626c2330f53f",
   "metadata": {},
   "source": [
    "we must verify that the cleaner does not create more docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72a0a468-dc44-4a49-a1a7-1b59720d5db6",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert len(docs2) <= len(docs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7792dd25-a171-431d-9345-30a72df7fc74",
   "metadata": {},
   "source": [
    "# ImageCleaner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24f77f56-b4c7-443b-8ec5-885ae1cca3bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "class ImageCleaner:\n",
    "    def __init__(self, path: str):\n",
    "        self.path = path\n",
    "\n",
    "    def clean(self):\n",
    "        pass"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
