{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# default_exp downloader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Downloader\n",
    "\n",
    "> `Downloaders` are a one of the main block of web2dataset. They define the code to scrap the web for multi-model data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hide\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hide\n",
    "from nbdev.showdoc import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "here is the abstract class for the Downloader "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "import os\n",
    "import urllib\n",
    "import uuid\n",
    "from abc import ABC, abstractmethod\n",
    "from typing import List, Optional\n",
    "\n",
    "from docarray import Document, DocumentArray"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "class Downloader(ABC):\n",
    "    \"\"\"\n",
    "    Base class abstract for any downloader\n",
    "\n",
    "    Example:\n",
    "    ```python\n",
    "    >>> from web2dataset import BasicDownloader\n",
    "    >>> downloader = BasicDownloader(path=\"dataset.bin\")\n",
    "    >>> downloader.download(\"wallpaper\", 2)\n",
    "    ```\n",
    "    \"\"\"\n",
    "\n",
    "    _DOCS_FILE_NAME = \"dataset.bin\"\n",
    "\n",
    "    def __init__(self, path: str):\n",
    "        \"\"\"\n",
    "        path: folder in which to save the files\n",
    "        \"\"\"\n",
    "        self.docs: DocumentArray = DocumentArray()\n",
    "\n",
    "        self.path = path[0:-2] if path[-1] == \"/\" else path\n",
    "\n",
    "        os.makedirs(path, exist_ok=True)\n",
    "\n",
    "    def download(self, query: str, n_item: int):\n",
    "        \"\"\"Scrap internet and download some files\n",
    "        query: a tag to define the download query\n",
    "        n_item: the number of file to download\n",
    "        \"\"\"\n",
    "        self._download(query,n_item)\n",
    "        self._save_docs()\n",
    "        \n",
    "    @abstractmethod\n",
    "    def _download(self, query: str, n_item: int):\n",
    "        ...\n",
    "\n",
    "    @property\n",
    "    def path_docs(self):\n",
    "        return f\"{self.path}/{self.__class__._DOCS_FILE_NAME}\"\n",
    "\n",
    "    def _save_docs(self):\n",
    "        \"\"\"Save the metadata\"\"\"\n",
    "        with open(self.path_docs, \"wb\") as f:\n",
    "            f.write(self.docs.to_bytes())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Example: simple Downloader:\n",
    "this class will be used of testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_folder = \"/tmp/test\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hide\n",
    "import shutil\n",
    "shutil.rmtree(test_folder,ignore_errors=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BasicDownloader(Downloader):\n",
    "    def _get_doc(self) -> Document:\n",
    "        return Document(\n",
    "            tag={\n",
    "                \"origin\": \"https://www.google.fr\",\n",
    "                \"image_url\": \"https://raw.githubusercontent.com/fastai/fastai/master/nbs/images/puppy.jpg\",\n",
    "            }\n",
    "        )\n",
    "\n",
    "    def _download(self, query: str, n_item: int):\n",
    "        self.docs.extend((self._get_doc() for _ in range(n_item)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "let's define a downloader that will search random wallpaper on the web"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "downloader = BasicDownloader(f\"{test_folder}/my_search\")\n",
    "downloader.download(\"wallpaper\", 2)\n",
    "assert len(downloader.docs) == 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Under the hood the `Downloader` save everything in memory in a `DocumentArray` from the [docarray](https://docarray.jina.ai/) package"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-style: italic\">            Documents Summary            </span>\n",
       "                                         \n",
       "  Length                 2               \n",
       "  Homogenous Documents   True            \n",
       "  Common Attributes      ('id', 'tags')  \n",
       "                                         \n",
       "<span style=\"font-style: italic\">                     Attributes Summary                     </span>\n",
       "                                                            \n",
       " <span style=\"font-weight: bold\"> Attribute </span> <span style=\"font-weight: bold\"> Data type </span> <span style=\"font-weight: bold\"> #Unique values </span> <span style=\"font-weight: bold\"> Has empty value </span> \n",
       " ────────────────────────────────────────────────────────── \n",
       "  id          ('str',)    2                False            \n",
       "  tags        ('dict',)   2                False            \n",
       "                                                            \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[3m            Documents Summary            \u001b[0m\n",
       "                                         \n",
       "  Length                 2               \n",
       "  Homogenous Documents   True            \n",
       "  Common Attributes      ('id', 'tags')  \n",
       "                                         \n",
       "\u001b[3m                     Attributes Summary                     \u001b[0m\n",
       "                                                            \n",
       " \u001b[1m \u001b[0m\u001b[1mAttribute\u001b[0m\u001b[1m \u001b[0m \u001b[1m \u001b[0m\u001b[1mData type\u001b[0m\u001b[1m \u001b[0m \u001b[1m \u001b[0m\u001b[1m#Unique values\u001b[0m\u001b[1m \u001b[0m \u001b[1m \u001b[0m\u001b[1mHas empty value\u001b[0m\u001b[1m \u001b[0m \n",
       " ────────────────────────────────────────────────────────── \n",
       "  id          ('str',)    2                False            \n",
       "  tags        ('dict',)   2                False            \n",
       "                                                            \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "downloader.docs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "we can now load the dataset in a `DocumentArray` to use it afterwards"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f\"{test_folder}/my_search/dataset.bin\", \"rb\") as f:\n",
    "    docs = DocumentArray.from_bytes(f.read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-style: italic\">            Documents Summary            </span>\n",
       "                                         \n",
       "  Length                 2               \n",
       "  Homogenous Documents   True            \n",
       "  Common Attributes      ('id', 'tags')  \n",
       "                                         \n",
       "<span style=\"font-style: italic\">                     Attributes Summary                     </span>\n",
       "                                                            \n",
       " <span style=\"font-weight: bold\"> Attribute </span> <span style=\"font-weight: bold\"> Data type </span> <span style=\"font-weight: bold\"> #Unique values </span> <span style=\"font-weight: bold\"> Has empty value </span> \n",
       " ────────────────────────────────────────────────────────── \n",
       "  id          ('str',)    2                False            \n",
       "  tags        ('dict',)   2                False            \n",
       "                                                            \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[3m            Documents Summary            \u001b[0m\n",
       "                                         \n",
       "  Length                 2               \n",
       "  Homogenous Documents   True            \n",
       "  Common Attributes      ('id', 'tags')  \n",
       "                                         \n",
       "\u001b[3m                     Attributes Summary                     \u001b[0m\n",
       "                                                            \n",
       " \u001b[1m \u001b[0m\u001b[1mAttribute\u001b[0m\u001b[1m \u001b[0m \u001b[1m \u001b[0m\u001b[1mData type\u001b[0m\u001b[1m \u001b[0m \u001b[1m \u001b[0m\u001b[1m#Unique values\u001b[0m\u001b[1m \u001b[0m \u001b[1m \u001b[0m\u001b[1mHas empty value\u001b[0m\u001b[1m \u001b[0m \n",
       " ────────────────────────────────────────────────────────── \n",
       "  id          ('str',)    2                False            \n",
       "  tags        ('dict',)   2                False            \n",
       "                                                            \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "docs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before jumping into creating actual `Downloader` let's define the core error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "class DownloaderError(ValueError):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ImageDownloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "class ImageDownloader(Downloader):\n",
    "    \"\"\"\n",
    "    Specialize abstract downloader for image\n",
    "    \"\"\"\n",
    "\n",
    "    _IMG_SUB_PATH = \"images\"\n",
    "\n",
    "    def __init__(self, path: str):\n",
    "        \"\"\"\n",
    "        path: folder in which to save the files\n",
    "        \"\"\"\n",
    "        super().__init__(path)\n",
    "        os.makedirs(self.path_image, exist_ok=True)\n",
    "\n",
    "    def _data_url_to_file(self, url: str, id_: str):\n",
    "        response = urllib.request.urlopen(url)\n",
    "        with open(f\"{self.path_image}/{id_}.jpg\", \"wb\") as f:\n",
    "            f.write(response.file.read())\n",
    "\n",
    "    @property\n",
    "    def path_image(self):\n",
    "        return f\"{self.path}/{self.__class__._IMG_SUB_PATH}\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Google Image Downloader\n",
    "\n",
    "> The Google Image Downloader is one of the main `Downloader` of web2dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "from contextlib import contextmanager\n",
    "\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from selenium.webdriver.chrome.webdriver import WebDriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.remote.webelement import WebElement"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "to use this tutorial you need to have installed the [chrome webdriver](https://chromedriver.chromium.org/downloads) which will play the role of the browser during the downloading"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "first lets design a simple context manager to open and close the web driver automatically"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "@contextmanager\n",
    "def _get_driver(debug=False):\n",
    "\n",
    "    if debug:\n",
    "        driver = webdriver.Chrome()\n",
    "    else:\n",
    "        chrome_options = Options()\n",
    "        chrome_options.add_argument(\"--headless\")\n",
    "        driver = webdriver.Chrome(options=chrome_options)\n",
    "    try:\n",
    "        yield driver\n",
    "    finally:\n",
    "        driver.quit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with _get_driver() as driver:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we can define the google image downloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "class GoogleImageDownloaderError(DownloaderError):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "class GoogleImageDownloader(ImageDownloader):\n",
    "    \"\"\"\n",
    "    GoogleImageDownloader: A downloader to download image from google images\n",
    "\n",
    "    Example:\n",
    "    ```python\n",
    "    >>> from web2dataset import GoogleImageDownloader\n",
    "    >>> downloader = GoogleImageDownloader()\n",
    "    >>> downloader.download(\"red bike\", 10)\n",
    "    >>> downloader.save(\"dataset.bin\")\n",
    "\n",
    "    ```\n",
    "    \"\"\"\n",
    "\n",
    "    def _download(self, query: str, n_item: int):\n",
    "        \"\"\"Scrap google image and download n_item images from the query\n",
    "        query: a tag to define the download query. The query should be of the form \"red bike\" and should not contain \"+\" as it is use internaly\n",
    "        n_item: the number of file to download\n",
    "        \"\"\"\n",
    "        google_image_url = self._create_url_from_query(query)\n",
    "        with _get_driver() as driver:\n",
    "\n",
    "            driver.get(google_image_url)\n",
    "\n",
    "            while _continue := len(self.docs) < n_item:\n",
    "\n",
    "                self._scrap_all_images_in_current_page(driver, query, n_item)\n",
    "                _continue = len(self.docs) < n_item\n",
    "\n",
    "                if _continue:\n",
    "                    self._scroll_to_next_page(driver)\n",
    "\n",
    "    def _create_url_from_query(self, query: str) -> str:\n",
    "        if \"+\" in query:\n",
    "            raise GoogleImageDownloaderError(\n",
    "                \" + should not be in the query because the whitespace are replaced by + so the meaning is different\"\n",
    "            )\n",
    "        return f\"https://www.google.com/search?q={query.replace(' ','+')}&source=lnms&tbm=isch\"\n",
    "\n",
    "    def _element_to_document(self, element, query: str):\n",
    "        \"\"\"\n",
    "        convert an google image element to a document\n",
    "        \"\"\"\n",
    "        url = element.get_attribute(\"src\")\n",
    "        id_ = str(uuid.uuid1())\n",
    "\n",
    "        self._data_url_to_file(url, id_)\n",
    "        doc = Document(origin=query, uri=f\"{self.__class__._IMG_SUB_PATH}/{id_}.jpg\", tag={\"uuid\": id_})\n",
    "        \n",
    "        return doc\n",
    "\n",
    "    def _find_images(self, driver: WebDriver) -> List[WebElement]:\n",
    "        return driver.find_elements(By.CLASS_NAME, \"rg_i\")\n",
    "\n",
    "    def _scrap_all_images_in_current_page(\n",
    "        self, driver: WebDriver, query: str, n_item: int\n",
    "    ):\n",
    "        elements = self._find_images(driver)\n",
    "        self.elements = elements\n",
    "        self.docs.extend(\n",
    "            [\n",
    "                self._element_to_document(e, query)\n",
    "                for i, e in enumerate(elements)\n",
    "                if len(self.docs) + i < n_item\n",
    "            ]\n",
    "        )\n",
    "\n",
    "    def _scroll_to_next_page(self, driver: WebDriver):\n",
    "        driver.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "downloader = GoogleImageDownloader(f\"{test_folder}/bikedataset\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_item = 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 43.9 ms, sys: 972 µs, total: 44.8 ms\n",
      "Wall time: 2.24 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "downloader.download(\"bike\", n_item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert len(downloader.docs) == n_item"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we downloaded our images let's plot them !"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'images/00fd9e78-9cab-11ec-b2e3-645d865124e9.jpg'"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "downloader.docs[0].uri"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_img(d):\n",
    "    d.uri = f\"{test_folder}/bikedataset/{d.uri}\"\n",
    "    d.load_uri_to_image_tensor()\n",
    "    return d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "downloader.docs = downloader.docs.apply(load_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "downloader.docs.plot_image_sprites()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hide\n",
    "shutil.rmtree(test_folder,ignore_errors=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
